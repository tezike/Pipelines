{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLM-Roberta_basic_xla.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMX1op62ZoI/QLi3xX3AEGo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2890794c5ba34289ac0d1248142c7ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0df96df55f7b4801a6e8f9709863db9b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a8cc8e49da7645d3aa0040e9590eca6b",
              "IPY_MODEL_3dbbba9495934125826dde3eeff2cb1c"
            ]
          }
        },
        "0df96df55f7b4801a6e8f9709863db9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8cc8e49da7645d3aa0040e9590eca6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51f9e43a4e4747f1b9a08f30b984a932",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbe8b9a2940e4d02a203e5ba665c8b8c"
          }
        },
        "3dbbba9495934125826dde3eeff2cb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e743cf67d844de78307ae4fa7cdfe6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/59 [00:14&lt;00:00,  4.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a54f9c4ea24460bb4ec9ed6e5ff734c"
          }
        },
        "51f9e43a4e4747f1b9a08f30b984a932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbe8b9a2940e4d02a203e5ba665c8b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e743cf67d844de78307ae4fa7cdfe6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a54f9c4ea24460bb4ec9ed6e5ff734c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd8471894b584861a0af0a35f9f079f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d595e373bfc41e99e1731c0a1088a7a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69b22e9847254b1bb1dc290ea5a1179c",
              "IPY_MODEL_1c65b77af8764bae9819dc9799674189"
            ]
          }
        },
        "0d595e373bfc41e99e1731c0a1088a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69b22e9847254b1bb1dc290ea5a1179c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fa0c5ccb32ae496382f07b39b5b85763",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b88f2d1a7a5341bca937c4acff84e5ac"
          }
        },
        "1c65b77af8764bae9819dc9799674189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_49d55e8e26174fa69651298da7324010",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/59 [13:50&lt;00:00, 14.08s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8716d08fc604dd9b2cf010801922668"
          }
        },
        "fa0c5ccb32ae496382f07b39b5b85763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b88f2d1a7a5341bca937c4acff84e5ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49d55e8e26174fa69651298da7324010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8716d08fc604dd9b2cf010801922668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "492acc1d6fb44cec89a18212b40acb14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ecaaf99190a34729b907f34897bb9ece",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d49e9fd3dd149aaa38c1e5bbcb1669b",
              "IPY_MODEL_920cdb7d0c134c359ba0576a2fddce5e"
            ]
          }
        },
        "ecaaf99190a34729b907f34897bb9ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d49e9fd3dd149aaa38c1e5bbcb1669b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ef3eb3e71580499b9d07b3e04a0f08a9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6f4012afbcb4dd9a9e8c1908ca2e2e7"
          }
        },
        "920cdb7d0c134c359ba0576a2fddce5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08d5fb96ee8f4362a573281a5067398c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/59 [08:11&lt;00:00,  8.34s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_830af8122f3443f4bf28ac3ea44f7553"
          }
        },
        "ef3eb3e71580499b9d07b3e04a0f08a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6f4012afbcb4dd9a9e8c1908ca2e2e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08d5fb96ee8f4362a573281a5067398c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "830af8122f3443f4bf28ac3ea44f7553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "916f1ea545b2480ba212ee67aed4f49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6386b091206645ae96252184488e908a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2e5de9fcf29434583fc711fb30d1de5",
              "IPY_MODEL_d0e716747b024feb862ce85f14cd55bc"
            ]
          }
        },
        "6386b091206645ae96252184488e908a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2e5de9fcf29434583fc711fb30d1de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94879d4104b647e5a2553f1f3ee93e02",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_340d1ffd1b8d4f7886b81d720f407dab"
          }
        },
        "d0e716747b024feb862ce85f14cd55bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c1dec34a4bd9487180967794d7d8bdff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/59 [04:12&lt;00:00,  4.28s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f79206e5283245f392fb2698a8d90b84"
          }
        },
        "94879d4104b647e5a2553f1f3ee93e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "340d1ffd1b8d4f7886b81d720f407dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1dec34a4bd9487180967794d7d8bdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f79206e5283245f392fb2698a8d90b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8056c47f010249b9bc1eb88d4a36cbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ffbadfe7de084975a1ebaa55ae0b7a69",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b996b107b7fb42cfbe94b18e9089b51a",
              "IPY_MODEL_647a6e5e46a642039057e1bcc6f7a16e"
            ]
          }
        },
        "ffbadfe7de084975a1ebaa55ae0b7a69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b996b107b7fb42cfbe94b18e9089b51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03c5e38a7d974a7d926097757ada7719",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e551f67ed75b44478f7ef3105f65b97b"
          }
        },
        "647a6e5e46a642039057e1bcc6f7a16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_345c35e4e6864102ae57e887d6f876b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/59 [00:06&lt;00:00,  9.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e594aea09434a129a256b407b497083"
          }
        },
        "03c5e38a7d974a7d926097757ada7719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e551f67ed75b44478f7ef3105f65b97b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "345c35e4e6864102ae57e887d6f876b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e594aea09434a129a256b407b497083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90a298d7d3e2419d80deda549cf2ba3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_77ede916532f4d20937aa747d9c0b552",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_27c0551dcd7e4ba9b1e7854c9c535149",
              "IPY_MODEL_9b3f3213a4974c698a642835ab273933"
            ]
          }
        },
        "77ede916532f4d20937aa747d9c0b552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27c0551dcd7e4ba9b1e7854c9c535149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b6e946f03ad74e90ae86c9c08500dfd8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a45c1bf37654f52ad8b5bfb14e8e948"
          }
        },
        "9b3f3213a4974c698a642835ab273933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_66f3a918da204e6d8bb2a7351002b731",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/59 [00:06&lt;00:00,  9.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3283cc45ffb043edb29acb3daf3310fd"
          }
        },
        "b6e946f03ad74e90ae86c9c08500dfd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a45c1bf37654f52ad8b5bfb14e8e948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66f3a918da204e6d8bb2a7351002b731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3283cc45ffb043edb29acb3daf3310fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVpqAMUEOeZL",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GniexJjK6gA8",
        "colab_type": "text"
      },
      "source": [
        "Prepping things up for TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga69MZG2OgYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5NpJHrwOh1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fef09570-9d10-4222-cbd7-373411cba9c2"
      },
      "source": [
        "VERSION = \"nightly\"  #@param [\"1.5\" , \"20200516\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4139  100  4139    0     0  17103      0 --:--:-- --:--:-- --:--:-- 17032\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-nightly ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (1.12.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (47.3.1)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.10.0)\n",
            "Uninstalling torch-1.5.1+cu101:\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Done updating TPU runtime\n",
            "  Successfully uninstalled torch-1.5.1+cu101\n",
            "Uninstalling torchvision-0.6.1+cu101:\n",
            "  Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][107.5 MiB/107.5 MiB]                                                \n",
            "Operation completed over 1 objects/107.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][123.9 MiB/123.9 MiB]                                                \n",
            "Operation completed over 1 objects/123.9 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.2 MiB/  2.2 MiB]                                                \n",
            "Operation completed over 1 objects/2.2 MiB.                                      \n",
            "Processing ./torch-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (0.16.0)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.7.0a0+6ef9459\n",
            "Processing ./torch_xla-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+8504a13\n",
            "Processing ./torchvision-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (7.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (1.7.0a0+6ef9459)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.8.0a0+4433a5b\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (379 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s29BtVjVana",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "def create_path(path):\n",
        "    if not os.path.isdir(path):\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "    return path\n",
        "\n",
        "colab_path = Path('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjp17fM_VU-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_path(colab_path/'dataset');\n",
        "create_path(colab_path/'models');\n",
        "\n",
        "!git clone --quiet 'https://github.com/tezike/download_google_drive.git'\n",
        "os.chdir('download_google_drive')\n",
        "!python download_gdrive.py '10rH0nAxa7mWS289xIyRP-mOOowqiIolL' '../dataset/temp.tgz'\n",
        "shutil.rmtree('../download_google_drive')\n",
        "os.chdir('..')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQNK70EuxrRr",
        "colab_type": "text"
      },
      "source": [
        "## Colab_setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdKS3nNT0IKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9759980b-a6b0-4a8f-a7b6-c0451f338548"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_dir = Path('/content/drive/My Drive')\n",
        "base_path = create_path(root_dir/'Rakuten')\n",
        "base_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/My Drive/Rakuten')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N3Yehzed8gZ",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-5fNbZ9gdbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7190da78-8fb9-43cb-cfa5-9a2826721569"
      },
      "source": [
        "!pip install transformers -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 778kB 3.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 14.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 33.3MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwVPUKqdd_UA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import string\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from tqdm import notebook\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCv3RE7Q6niW",
        "colab_type": "text"
      },
      "source": [
        "prepping things up for TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t9yDuRfOBom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm #handles most of the basic tasks\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl #handles dataloading on multiple processes\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YehI1cgeeL1r",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_-dDMrQeOjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.MODEL_NAME = 'camembert-base'\n",
        "        # self.LM_MODEL = transformers.CambertForMaskedLM.from_pretrained(self.MODEL_NAME)\n",
        "        self.CLAS_MODEL = transformers.CamembertModel #.from_pretrained(MODEL_NAME)\n",
        "        self.TOKENIZER = transformers.CamembertTokenizer.from_pretrained(\n",
        "                    pretrained_model_name_or_path=self.MODEL_NAME,\n",
        "                    do_lower_case=True,\n",
        "                    )\n",
        "        self.MODEL_CONFIG = transformers.CamembertConfig.from_pretrained(self.MODEL_NAME)\n",
        "        self.COLAB_PATH = Path('/content')\n",
        "        self.BASE_PATH = base_path\n",
        "        self.DATA_PATH = create_path(base_path/'dataset')\n",
        "        self.MODEL_PATH = create_path(base_path/'models')\n",
        "        self.TEST_FILE = self.COLAB_PATH/'SIGIR-2020-EComDC-release/data/x_test_task1_phase1.tsv'\n",
        "        self.CLEAN_DF = self.DATA_PATH/'clean_folds_df.csv'\n",
        "        self.MAX_SEQ_LEN = 256\n",
        "        self.DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.TRAIN_BATCH_SIZE = 32\n",
        "        self.VALID_BATCH_SIZE = 16\n",
        "        self.NUM_EPOCHS = 10\n",
        "\n",
        "config = Config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqPwYfdFde8g",
        "colab_type": "text"
      },
      "source": [
        "## DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztg_Iy6hV1VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, label):\n",
        "        self.text, self.label = text, label\n",
        "        self.tokenizer = config.TOKENIZER\n",
        "        self.max_len = config.MAX_SEQ_LEN\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # sanity check\n",
        "        text = ' '.join(self.text[i].split())\n",
        "\n",
        "        # tokenize using Huggingface tokenizers\n",
        "        out = self.tokenizer.encode_plus(text, None, \n",
        "                                   add_special_tokens=True, \n",
        "                                   max_length = self.max_len,\n",
        "                                   truncation = True)\n",
        "        \n",
        "        ids = out['input_ids']\n",
        "        mask = out['attention_mask']\n",
        "        \n",
        "        padding_length = self.max_len - len(ids)\n",
        "        ids = ids + ([0] * padding_length)\n",
        "        mask = mask + ([0] * padding_length)\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.label[i], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCZqMIycty9o",
        "colab_type": "text"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQexDRqat0TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter():\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QG7YhMnfVeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EarlyStopping():\n",
        "    def __init__(self, patience=7, mode=\"max\", delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.mode = mode\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "        if self.mode == \"min\":\n",
        "            self.val_score = np.Inf\n",
        "        else:\n",
        "            self.val_score = -np.Inf\n",
        "\n",
        "    def __call__(self, epoch_score, model, model_path):\n",
        "\n",
        "        if self.mode == \"min\":\n",
        "            score = -1.0 * epoch_score\n",
        "        else:\n",
        "            score = np.copy(epoch_score)\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(epoch_score, model, model_path)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            xm.master_print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(epoch_score, model, model_path)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, epoch_score, model, model_path):\n",
        "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
        "            xm.master_print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))\n",
        "#             torch.save(model.state_dict(), model_path)\n",
        "            xm.save(model.state_dict(), model_path)\n",
        "        self.val_score = epoch_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0vs7hY5lScN",
        "colab_type": "text"
      },
      "source": [
        "## MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Rwh_l2oiB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClasModel(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=27):\n",
        "        super(ClasModel, self).__init__()\n",
        "        if pretrained:\n",
        "            self.model = config.CLAS_MODEL.from_pretrained(config.MODEL_NAME, config=config.MODEL_CONFIG)\n",
        "        else: \n",
        "            self.model = config.CLAS_MODEL(config.MODEL_CONFIG)\n",
        "                  \n",
        "        self.drop = nn.Dropout(0.4)\n",
        "\n",
        "        self.lin = nn.Linear(768*2, num_classes)\n",
        "    \n",
        "    def forward(self, ids, mask):\n",
        "\n",
        "        h_0, _ = self.model(ids, attention_mask=mask)\n",
        "        \n",
        "        mean_pool = torch.mean(h_0, 1)\n",
        "\n",
        "        max_pool = torch.max(h_0, 1)[0]\n",
        "\n",
        "        out = torch.cat([mean_pool, max_pool], 1)\n",
        "\n",
        "        out = self.lin(self.drop(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "    # def load_lm_encoder(self,clas_model, lm_path=None):\n",
        "    #     clas_model_dict = clas_model.state_dict()\n",
        "    #     if lm_path is not None:\n",
        "    #         lm_model_dict = torch.load(lm_path).model.state_dict()\n",
        "    #         needed_dict = {k[6:]:v for k, v in lm_model_dict.items() if str(k)[6:] in clas_model_dict.keys()}\n",
        "    #         clas_model_dict.update(needed_dict)\n",
        "    #     clas_model.load_state_dict(clas_model_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS1GRp6pxmH5",
        "colab_type": "text"
      },
      "source": [
        "## Prep data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWMSkVxhTFF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf $colab_path/'dataset/temp.tgz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yshyZqfaZ9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
        "    and remove words containing numbers.'''\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7j6aWiRxper",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_all = pd.read_csv(config.BASE_PATH/'dataset/df_all.csv').sample(frac=1).reset_index(drop=True); \n",
        "# df_all.fillna(' ', inplace=True)\n",
        "# df_all.Title = df_all.Title.apply(str).apply(lambda x: clean_text(x))\n",
        "# df_all.Description = df_all.Description.apply(str).apply(lambda x: clean_text(x))\n",
        "# y = df_all.Prdlbl.values\n",
        "# df_all.sample(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcQb5lhhZ5SZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# le = LabelEncoder()\n",
        "# le.fit(df_all.Prdlbl)\n",
        "# le.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3AYX8xQaL6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_all.Prdlbl = le.transform(df_all.Prdlbl)\n",
        "# df_all['fold'] = -1\n",
        "\n",
        "# kfold = StratifiedKFold(5, shuffle=True)\n",
        "\n",
        "# for i, (trn, val) in enumerate(kfold.split(X=df_all, y=y)):\n",
        "#     df_all.loc[val, 'fold'] = i\n",
        "\n",
        "# df_all.to_csv(config.CLEAN_DF, index=False)\n",
        "\n",
        "# df_all = pd.read_csv(config.CLEAN_DF)\n",
        "# df_all.fillna(' ', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liOgFinoELey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ee9b700a-897c-4157-9991-7203188ef78c"
      },
      "source": [
        "#run this instead\n",
        "df_all = pd.read_csv(config.CLEAN_DF)\n",
        "df_all.fillna(' ', inplace=True)\n",
        "\n",
        "temp_df = pd.read_csv(config.BASE_PATH/'dataset/df_all.csv').sample(frac=1).reset_index(drop=True)\n",
        "le = LabelEncoder()\n",
        "le.fit(temp_df.Prdlbl)\n",
        "le.transform(le.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNZuUsRAqFC5",
        "colab_type": "text"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCBYR452tqJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WRAPPED_MODEL = xmp.MpModelWrapper(ClasModel(pretrained=True))\n",
        "def world_func(fold):\n",
        "    xm.master_print(f'Running Fold {fold}')\n",
        "    xtra_config = config.MODEL_CONFIG\n",
        "    device = xm.xla_device()\n",
        "    model_path = config.MODEL_PATH/f'torch_xla_pretrained_xla_roberta_fold{fold}.bin'\n",
        "\n",
        "    global WRAPPED_MODEL\n",
        "    model = WRAPPED_MODEL.to(device)\n",
        "\n",
        "    def loss_fn(y_pred, y_true):\n",
        "        return nn.CrossEntropyLoss()(y_pred, y_true)\n",
        "\n",
        "    def train(train_dl, model, optimizer, device, scheduler=None):\n",
        "        xm.master_print('Training...')\n",
        "        model.train()\n",
        "        loss_all = AverageMeter()\n",
        "\n",
        "        # p_bar = notebook.tqdm(train_dl, total=len(train_dl))\n",
        "        for i, batch in enumerate(train_dl):\n",
        "            ids = batch['ids']\n",
        "            mask = batch['mask']\n",
        "            targets = batch['targets']\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            model.zero_grad()\n",
        "            out = model(ids, mask)\n",
        "\n",
        "            loss = loss_fn(out, targets)\n",
        "            loss_all.update(loss.detach().item(), ids.size(0))\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                xm.master_print(f'Batch: {i}, Training loss: {loss_all.avg}')\n",
        "\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer)\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "            \n",
        "            # break\n",
        "        \n",
        "        # p_bar.set_postfix(loss=loss_all.avg)\n",
        "\n",
        "    def evaluate(valid_dl, model, device):\n",
        "        xm.master_print('Evaluating...')\n",
        "        model.eval()\n",
        "        fin_targs = []\n",
        "        fin_outs = []\n",
        "        losses = 0.\n",
        "        loss_all = AverageMeter()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # p_bar = notebook.tqdm(valid_dl, total=len(valid_dl))\n",
        "            for i, batch in enumerate(valid_dl):\n",
        "                ids = batch['ids']\n",
        "                mask = batch['mask']\n",
        "                targets = batch['targets']\n",
        "\n",
        "                ids = ids.to(device, dtype=torch.long)\n",
        "                mask = mask.to(device, dtype=torch.long)\n",
        "                targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "                out = model(ids, mask)\n",
        "                loss = loss_fn(out, targets)\n",
        "\n",
        "                loss_all.update(loss.detach().item(), ids.size(0))\n",
        "\n",
        "                if i % 100 == 0:\n",
        "                    xm.master_print(f'Batch: {i}, Evaluation loss: {loss_all.avg}')\n",
        "\n",
        "                targ_np = targets.cpu().detach().numpy().tolist()\n",
        "\n",
        "                soft_out = nn.Softmax(dim=1)(out.cpu().detach())\n",
        "                out_np = soft_out.argmax(-1).numpy().tolist()\n",
        "\n",
        "                fin_targs.extend(targ_np)\n",
        "                fin_outs.extend(out_np)\n",
        "                # break\n",
        "\n",
        "            # p_bar.set_postfix(loss=loss_all.avg)\n",
        "        return fin_targs, fin_outs, losses\n",
        "\n",
        "\n",
        "    train_df, valid_df = df_all.query(f'fold != {fold}'), df_all.query(f'fold == {fold}')\n",
        "    train_df.reset_index(drop=True, inplace=True), valid_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    train_ds = BertDataset((train_df.Title + 'xxfld' + train_df.Description).values, train_df.Prdlbl.values)\n",
        "    valid_ds = BertDataset((valid_df.Title + 'xxfld' + valid_df.Description).values, valid_df.Prdlbl.values)\n",
        "\n",
        "    ###########change happens here#####################\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_ds, \n",
        "                                                                    num_replicas=xm.xrt_world_size(),\n",
        "                                                                    rank=xm.get_ordinal(),\n",
        "                                                                    shuffle=True)\n",
        "    ###################################################\n",
        "\n",
        "    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=config.TRAIN_BATCH_SIZE, \n",
        "                                        drop_last=True, num_workers=4, \n",
        "                                        sampler=train_sampler)\n",
        "\n",
        "    ###########change happens here#####################\n",
        "    valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_ds, \n",
        "                                                                    num_replicas=xm.xrt_world_size(),\n",
        "                                                                    rank=xm.get_ordinal(),\n",
        "                                                                    shuffle=False)\n",
        "    ###################################################\n",
        "\n",
        "    valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=config.VALID_BATCH_SIZE, \n",
        "                                        drop_last=False, num_workers=4,\n",
        "                                        sampler=valid_sampler)\n",
        "\n",
        "\n",
        "    ############change happens here################\n",
        "    lr = 1e-05 * xm.xrt_world_size()\n",
        "    #############################\n",
        "\n",
        "    es = EarlyStopping(patience=4, mode='max')\n",
        "\n",
        "    model_params = list(model.named_parameters())\n",
        "    # print('after model')\n",
        "\n",
        "    # we don't want weight decay for these\n",
        "    no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n",
        "\n",
        "    optimizer_params = [\n",
        "        {'params': [p for n, p in model_params if n not in no_decay], \n",
        "        'weight_decay':0.001},\n",
        "        #  no weight decay should be applied\n",
        "        {'params': [p for n, p in model_params if n in no_decay],\n",
        "        'weight_decay':0.0}\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_params, lr=lr)\n",
        "\n",
        "    ###############change happens here#########################\n",
        "    # scheduler\n",
        "    num_train_steps = int(len(train_df)/ config.TRAIN_BATCH_SIZE / xm.xrt_world_size() * config.NUM_EPOCHS)\n",
        "    ###########################################################\n",
        "\n",
        "    xm.master_print(f'num_train_steps = {num_train_steps}, world_size = {xm.xrt_world_size()}')\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, \n",
        "                                                num_warmup_steps=0, \n",
        "                                                num_training_steps=num_train_steps)\n",
        "\n",
        "    best_accuracy = 0.\n",
        "    for epoch in range(config.NUM_EPOCHS):\n",
        "        start_epoch = time.time()\n",
        "        xm.master_print('-'*50)\n",
        "        xm.master_print(f'Running Epoch #{epoch} {\"🔥\"*epoch}')\n",
        "        xm.master_print(f'{\"-\"*50} \\n')\n",
        "\n",
        "        train_para_loader = pl.ParallelLoader(train_dl, [device])\n",
        "        valid_para_loader = pl.ParallelLoader(train_dl, [device])\n",
        "\n",
        "        start = time.time()\n",
        "        train(train_para_loader.per_device_loader(device), model, optimizer, device, scheduler)\n",
        "        end = time.time()\n",
        "        xm.master_print(f'Training time: {round(end-start, 2)} secs')\n",
        "\n",
        "        start = time.time()\n",
        "        fin_targs, fin_outs, losses = evaluate(valid_para_loader.per_device_loader(device), model, device)\n",
        "        end = time.time()\n",
        "        xm.master_print(f'Evaluation time: {round(end-start, 2)} secs \\n')\n",
        "\n",
        "        # calc metrics\n",
        "        accuracy = accuracy_score(fin_targs, fin_outs)\n",
        "        macro_f1 = f1_score(fin_targs, fin_outs, average='macro')\n",
        "\n",
        "        xm.master_print(f'VALID ACCURACY: {accuracy}')\n",
        "        xm.master_print(f'VALID MACRO_F1: {macro_f1}')\n",
        "        \n",
        "        # if accuracy > best_accuracy:\n",
        "        #     best_accuracy = accuracy\n",
        "        #     xm.save(model.state_dict(), model_path)\n",
        "\n",
        "        es(macro_f1, model, model_path=model_path)\n",
        "        if es.early_stop:\n",
        "            xm.master_print('Early Stopping...')\n",
        "            break\n",
        "\n",
        "        end_epoch = time.time()\n",
        "\n",
        "        xm.master_print(f'Total time: {round(end-start, 2)} secs \\n')\n",
        "\n",
        "        # break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Cozp1poA3t",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIcNfMl-TiO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_inference(fold):\n",
        "    test_df = pd.read_csv(config.COLAB_PATH/'SIGIR-2020-EComDC-release/data/x_test_task1_phase1.tsv', sep='\\t').fillna(' ')\n",
        "    model_path = config.MODEL_PATH/f'torch_xla_pretrained_xla_roberta_fold{fold}.bin'\n",
        "    test_df['Prdlbl'] = 0\n",
        "\n",
        "    test_ds = BertDataset((test_df.Title + 'xxfld' + test_df.Description).values, test_df.Prdlbl.values)\n",
        "\n",
        "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=config.VALID_BATCH_SIZE, \n",
        "                                            num_workers=4, shuffle=False)\n",
        "    \n",
        "    device = xm.xla_device()\n",
        "    model = ClasModel(pretrained=True).to(device)\n",
        "    model.load_state_dict(torch.load(str(model_path)))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    fin_outs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for bi, batch in tqdm(enumerate(test_dl), total=len(test_dl)):\n",
        "            ids = batch['ids']\n",
        "            mask = batch['mask']\n",
        "            targets = batch['targets']\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "            # model.zero_grad()\n",
        "            out = model(ids, mask)\n",
        "\n",
        "            soft_out = nn.Softmax(dim=1)(out.cpu().detach())\n",
        "            out_np = soft_out.argmax(-1).numpy().tolist()\n",
        "\n",
        "            fin_outs.extend(out_np)\n",
        "\n",
        "\n",
        "    sub_df = test_df.copy()\n",
        "    sub_df['Prdtypecode'] = le.inverse_transform(fin_outs)\n",
        "    sub_df.head()\n",
        "    sub_df[['Integer_id', 'Image_id', 'Product_id', 'Prdtypecode']].to_csv(config.DATA_PATH/f'y_test_task1_phase1_pred_fold{fold}.tsv', index=False, sep='\\t')\n",
        "\n",
        "    # Also save to colab\n",
        "    sub_df[['Integer_id', 'Image_id', 'Product_id', 'Prdtypecode']].to_csv(config.COLAB_PATH/f'y_test_task1_phase1_pred_fold{fold}.tsv', index=False, sep='\\t')\n",
        "    \n",
        "    print(f\"Submission file saved at: \\n {config.DATA_PATH}/'y_test_task1_phase1_pred_fold{fold}.tsv'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viI25DLyZJLy",
        "colab_type": "text"
      },
      "source": [
        "## Fin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHdDM9aQnuUf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e735325-9ae9-437f-eb9f-c17b21efefd0"
      },
      "source": [
        "import gc; gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1171"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLjVI0gyaMD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2890794c5ba34289ac0d1248142c7ea0",
            "0df96df55f7b4801a6e8f9709863db9b",
            "a8cc8e49da7645d3aa0040e9590eca6b",
            "3dbbba9495934125826dde3eeff2cb1c",
            "51f9e43a4e4747f1b9a08f30b984a932",
            "cbe8b9a2940e4d02a203e5ba665c8b8c",
            "8e743cf67d844de78307ae4fa7cdfe6e",
            "7a54f9c4ea24460bb4ec9ed6e5ff734c"
          ]
        },
        "outputId": "308e40a8-b702-4ec1-d12b-a07a6b7af63b"
      },
      "source": [
        "fold = 0\n",
        "FLAGS = {}\n",
        "def mp_wrapper(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    world_func(fold)\n",
        "\n",
        "xmp.spawn(mp_wrapper, args=(FLAGS,), nprocs=8, start_method='fork')\n",
        "\n",
        "# run inference\n",
        "make_inference(fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Fold 0\n",
            "num_train_steps = 2653, world_size = 8\n",
            "--------------------------------------------------\n",
            "Running Epoch #0 \n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 3.3006930351257324\n",
            "Batch: 100, Training loss: 2.2969900759139863\n",
            "Batch: 200, Training loss: 1.782161213568787\n",
            "Training time: 347.63 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.9767934679985046\n",
            "Batch: 100, Evaluation loss: 0.7326810224221485\n",
            "Batch: 200, Evaluation loss: 0.7430760172469106\n",
            "Evaluation time: 107.66 secs \n",
            "\n",
            "VALID ACCURACY: 0.8397405660377358\n",
            "VALID MACRO_F1: 0.7941439795245313\n",
            "Validation score improved (-inf --> 0.7941439795245313). Saving model!\n",
            "Total time: 107.66 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #1 🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 1.0407016277313232\n",
            "Batch: 100, Training loss: 0.6969152792255477\n",
            "Batch: 200, Training loss: 0.6627295613288879\n",
            "Training time: 321.98 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.7322834134101868\n",
            "Batch: 100, Evaluation loss: 0.4597646046688061\n",
            "Batch: 200, Evaluation loss: 0.4641814162926887\n",
            "Evaluation time: 120.52 secs \n",
            "\n",
            "VALID ACCURACY: 0.8816037735849057\n",
            "VALID MACRO_F1: 0.8479136073768546\n",
            "Validation score improved (0.7941439795245313 --> 0.8479136073768546). Saving model!\n",
            "Total time: 120.52 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #2 🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.8298268914222717\n",
            "Batch: 100, Training loss: 0.4550019101341172\n",
            "Batch: 200, Training loss: 0.4522002868687929\n",
            "Training time: 342.67 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.5312434434890747\n",
            "Batch: 100, Evaluation loss: 0.32147794504566946\n",
            "Batch: 200, Evaluation loss: 0.3251326098222638\n",
            "Evaluation time: 115.0 secs \n",
            "\n",
            "VALID ACCURACY: 0.9173349056603773\n",
            "VALID MACRO_F1: 0.903580015994666\n",
            "Validation score improved (0.8479136073768546 --> 0.903580015994666). Saving model!\n",
            "Total time: 115.0 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #3 🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.6472568511962891\n",
            "Batch: 100, Training loss: 0.3365868459833731\n",
            "Batch: 200, Training loss: 0.3529706547657649\n",
            "Training time: 343.69 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.40423092246055603\n",
            "Batch: 100, Evaluation loss: 0.26143525854343236\n",
            "Batch: 200, Evaluation loss: 0.2610303919521434\n",
            "Evaluation time: 116.28 secs \n",
            "\n",
            "VALID ACCURACY: 0.932311320754717\n",
            "VALID MACRO_F1: 0.9238184276877042\n",
            "Validation score improved (0.903580015994666 --> 0.9238184276877042). Saving model!\n",
            "Total time: 116.28 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #4 🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.4496432840824127\n",
            "Batch: 100, Training loss: 0.27412879618235153\n",
            "Batch: 200, Training loss: 0.2747691265905081\n",
            "Training time: 343.44 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.3204936981201172\n",
            "Batch: 100, Evaluation loss: 0.21409404052808734\n",
            "Batch: 200, Evaluation loss: 0.21835809734775058\n",
            "Evaluation time: 119.91 secs \n",
            "\n",
            "VALID ACCURACY: 0.9415094339622642\n",
            "VALID MACRO_F1: 0.9339716575729118\n",
            "Validation score improved (0.9238184276877042 --> 0.9339716575729118). Saving model!\n",
            "Total time: 119.91 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #5 🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.4314916729927063\n",
            "Batch: 100, Training loss: 0.2262462584098967\n",
            "Batch: 200, Training loss: 0.22473026574844152\n",
            "Training time: 344.87 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.23838134109973907\n",
            "Batch: 100, Evaluation loss: 0.16801574197367275\n",
            "Batch: 200, Evaluation loss: 0.17059402632995033\n",
            "Evaluation time: 117.15 secs \n",
            "\n",
            "VALID ACCURACY: 0.9571933962264151\n",
            "VALID MACRO_F1: 0.9506531206013201\n",
            "Validation score improved (0.9339716575729118 --> 0.9506531206013201). Saving model!\n",
            "Total time: 117.15 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #6 🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.37444978952407837\n",
            "Batch: 100, Training loss: 0.18231614701228566\n",
            "Batch: 200, Training loss: 0.18429072562660745\n",
            "Training time: 346.13 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.1674642264842987\n",
            "Batch: 100, Evaluation loss: 0.13110718278601619\n",
            "Batch: 200, Evaluation loss: 0.13461188047160558\n",
            "Evaluation time: 119.43 secs \n",
            "\n",
            "VALID ACCURACY: 0.9695754716981132\n",
            "VALID MACRO_F1: 0.9664691242055236\n",
            "Validation score improved (0.9506531206013201 --> 0.9664691242055236). Saving model!\n",
            "Total time: 119.43 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #7 🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.19390219449996948\n",
            "Batch: 100, Training loss: 0.15448286884123147\n",
            "Batch: 200, Training loss: 0.15864649288986452\n",
            "Training time: 349.55 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.17521604895591736\n",
            "Batch: 100, Evaluation loss: 0.10453935720874827\n",
            "Batch: 200, Evaluation loss: 0.10978253248763915\n",
            "Evaluation time: 115.79 secs \n",
            "\n",
            "VALID ACCURACY: 0.9759433962264151\n",
            "VALID MACRO_F1: 0.9732552099290207\n",
            "Validation score improved (0.9664691242055236 --> 0.9732552099290207). Saving model!\n",
            "Total time: 115.79 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #8 🔥🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.2727586627006531\n",
            "Batch: 100, Training loss: 0.125328671537561\n",
            "Batch: 200, Training loss: 0.13053182759484397\n",
            "Training time: 346.55 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.12222321331501007\n",
            "Batch: 100, Evaluation loss: 0.0835903761262941\n",
            "Batch: 200, Evaluation loss: 0.09184253443291976\n",
            "Evaluation time: 116.67 secs \n",
            "\n",
            "VALID ACCURACY: 0.9795990566037736\n",
            "VALID MACRO_F1: 0.977096177212812\n",
            "Validation score improved (0.9732552099290207 --> 0.977096177212812). Saving model!\n",
            "Total time: 116.67 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #9 🔥🔥🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.19446708261966705\n",
            "Batch: 100, Training loss: 0.09877285429525494\n",
            "Batch: 200, Training loss: 0.11227977502887225\n",
            "Training time: 345.3 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.08708669990301132\n",
            "Batch: 100, Evaluation loss: 0.0715186000884612\n",
            "Batch: 200, Evaluation loss: 0.08200255842573607\n",
            "Evaluation time: 119.31 secs \n",
            "\n",
            "VALID ACCURACY: 0.9821933962264151\n",
            "VALID MACRO_F1: 0.9796532590641378\n",
            "Validation score improved (0.977096177212812 --> 0.9796532590641378). Saving model!\n",
            "Total time: 119.31 secs \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2890794c5ba34289ac0d1248142c7ea0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Submission file saved at: \n",
            " /content/drive/My Drive/Rakuten/dataset/'y_test_task1_phase1_pred_fold0.tsv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRgOT_8jNwWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "cd8471894b584861a0af0a35f9f079f6",
            "0d595e373bfc41e99e1731c0a1088a7a",
            "69b22e9847254b1bb1dc290ea5a1179c",
            "1c65b77af8764bae9819dc9799674189",
            "fa0c5ccb32ae496382f07b39b5b85763",
            "b88f2d1a7a5341bca937c4acff84e5ac",
            "49d55e8e26174fa69651298da7324010",
            "c8716d08fc604dd9b2cf010801922668"
          ]
        },
        "outputId": "a024e537-120a-404a-cfe0-20c438d90fb4"
      },
      "source": [
        "make_inference(fold=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd8471894b584861a0af0a35f9f079f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Submission file saved at: \n",
            " /content/drive/My Drive/Rakuten/dataset/'y_test_task1_phase1_pred_fold1.tsv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACd8V2NPtJJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7e7a908-0f6e-4732-90bd-d57d06ed8eb9"
      },
      "source": [
        "fold = 1\n",
        "FLAGS = {}\n",
        "def mp_wrapper(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    world_func(fold)\n",
        "\n",
        "xmp.spawn(mp_wrapper, args=(FLAGS,), nprocs=8, start_method='fork')\n",
        "\n",
        "# run inference\n",
        "make_inference(fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Fold 1\n",
            "num_train_steps = 2653, world_size = 8\n",
            "--------------------------------------------------\n",
            "Running Epoch #0 \n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 3.311984062194824\n",
            "Batch: 100, Training loss: 2.31468132108745\n",
            "Batch: 200, Training loss: 1.784091452460977\n",
            "Training time: 369.89 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.7396478056907654\n",
            "Batch: 100, Evaluation loss: 0.7432409026245079\n",
            "Batch: 200, Evaluation loss: 0.7306556246470456\n",
            "Evaluation time: 112.36 secs \n",
            "\n",
            "VALID ACCURACY: 0.8413915094339622\n",
            "VALID MACRO_F1: 0.78413319658671\n",
            "Validation score improved (-inf --> 0.78413319658671). Saving model!\n",
            "Total time: 112.36 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #1 🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.7491677403450012\n",
            "Batch: 100, Training loss: 0.7152793224495236\n",
            "Batch: 200, Training loss: 0.6621590823824726\n",
            "Training time: 341.54 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.48904526233673096\n",
            "Batch: 100, Evaluation loss: 0.4563163160392554\n",
            "Batch: 200, Evaluation loss: 0.446128692348205\n",
            "Evaluation time: 116.82 secs \n",
            "\n",
            "VALID ACCURACY: 0.8896226415094339\n",
            "VALID MACRO_F1: 0.8569410183246555\n",
            "Validation score improved (0.78413319658671 --> 0.8569410183246555). Saving model!\n",
            "Total time: 116.82 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #2 🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.5145109295845032\n",
            "Batch: 100, Training loss: 0.4825799111092445\n",
            "Batch: 200, Training loss: 0.4620305506225249\n",
            "Training time: 339.32 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.4624159038066864\n",
            "Batch: 100, Evaluation loss: 0.3299456647790895\n",
            "Batch: 200, Evaluation loss: 0.3208538882286098\n",
            "Evaluation time: 116.12 secs \n",
            "\n",
            "VALID ACCURACY: 0.9189858490566037\n",
            "VALID MACRO_F1: 0.902085162408229\n",
            "Validation score improved (0.8569410183246555 --> 0.902085162408229). Saving model!\n",
            "Total time: 116.12 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #3 🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.44713521003723145\n",
            "Batch: 100, Training loss: 0.3717118422731315\n",
            "Batch: 200, Training loss: 0.35129666754707173\n",
            "Training time: 340.41 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.28341978788375854\n",
            "Batch: 100, Evaluation loss: 0.24964467126249087\n",
            "Batch: 200, Evaluation loss: 0.24387059325528382\n",
            "Evaluation time: 117.64 secs \n",
            "\n",
            "VALID ACCURACY: 0.9380896226415094\n",
            "VALID MACRO_F1: 0.9248581757234241\n",
            "Validation score improved (0.902085162408229 --> 0.9248581757234241). Saving model!\n",
            "Total time: 117.64 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #4 🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.3124009370803833\n",
            "Batch: 100, Training loss: 0.2886917665969617\n",
            "Batch: 200, Training loss: 0.28038251467642206\n",
            "Training time: 346.11 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.10669142007827759\n",
            "Batch: 100, Evaluation loss: 0.1906244793888366\n",
            "Batch: 200, Evaluation loss: 0.1902029239086073\n",
            "Evaluation time: 119.25 secs \n",
            "\n",
            "VALID ACCURACY: 0.9529481132075471\n",
            "VALID MACRO_F1: 0.9432765622271014\n",
            "Validation score improved (0.9248581757234241 --> 0.9432765622271014). Saving model!\n",
            "Total time: 119.25 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #5 🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.2335754930973053\n",
            "Batch: 100, Training loss: 0.23252647825618192\n",
            "Batch: 200, Training loss: 0.22541525314066244\n",
            "Training time: 349.21 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.10587489604949951\n",
            "Batch: 100, Evaluation loss: 0.14561220184706225\n",
            "Batch: 200, Evaluation loss: 0.14459825852024022\n",
            "Evaluation time: 119.51 secs \n",
            "\n",
            "VALID ACCURACY: 0.9647405660377358\n",
            "VALID MACRO_F1: 0.957047154358707\n",
            "Validation score improved (0.9432765622271014 --> 0.957047154358707). Saving model!\n",
            "Total time: 119.51 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #6 🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.2547185719013214\n",
            "Batch: 100, Training loss: 0.18212393914708996\n",
            "Batch: 200, Training loss: 0.17643948141207447\n",
            "Training time: 346.36 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.0616462267935276\n",
            "Batch: 100, Evaluation loss: 0.11873866328139707\n",
            "Batch: 200, Evaluation loss: 0.11714552763608557\n",
            "Evaluation time: 115.22 secs \n",
            "\n",
            "VALID ACCURACY: 0.9735849056603774\n",
            "VALID MACRO_F1: 0.9666341060606229\n",
            "Validation score improved (0.957047154358707 --> 0.9666341060606229). Saving model!\n",
            "Total time: 115.22 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #7 🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.12046296894550323\n",
            "Batch: 100, Training loss: 0.14990491490110314\n",
            "Batch: 200, Training loss: 0.1478752709128222\n",
            "Training time: 344.04 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.05813228711485863\n",
            "Batch: 100, Evaluation loss: 0.09895344867859737\n",
            "Batch: 200, Evaluation loss: 0.0982713888524406\n",
            "Evaluation time: 119.73 secs \n",
            "\n",
            "VALID ACCURACY: 0.9784198113207547\n",
            "VALID MACRO_F1: 0.9734177036532142\n",
            "Validation score improved (0.9666341060606229 --> 0.9734177036532142). Saving model!\n",
            "Total time: 119.73 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #8 🔥🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.09565895050764084\n",
            "Batch: 100, Training loss: 0.12360911435530622\n",
            "Batch: 200, Training loss: 0.12451877805001255\n",
            "Training time: 348.82 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.034380506724119186\n",
            "Batch: 100, Evaluation loss: 0.08073577258071982\n",
            "Batch: 200, Evaluation loss: 0.08009208260168929\n",
            "Evaluation time: 121.5 secs \n",
            "\n",
            "VALID ACCURACY: 0.9827830188679245\n",
            "VALID MACRO_F1: 0.9776554220618116\n",
            "Validation score improved (0.9734177036532142 --> 0.9776554220618116). Saving model!\n",
            "Total time: 121.5 secs \n",
            "\n",
            "--------------------------------------------------\n",
            "Running Epoch #9 🔥🔥🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.03194452449679375\n",
            "Batch: 100, Training loss: 0.10440279604258514\n",
            "Batch: 200, Training loss: 0.10402439490183076\n",
            "Training time: 348.73 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.05006101354956627\n",
            "Batch: 100, Evaluation loss: 0.07353199569342456\n",
            "Batch: 200, Evaluation loss: 0.07415003367973055\n",
            "Evaluation time: 118.01 secs \n",
            "\n",
            "VALID ACCURACY: 0.9837264150943397\n",
            "VALID MACRO_F1: 0.9794103281623897\n",
            "Validation score improved (0.9776554220618116 --> 0.9794103281623897). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e55a66988613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mworld_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     76\u001b[0m         ready = multiprocessing.connection.wait(\n\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         )\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDaDJRJQtJGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64eb4f37-c42b-4036-9794-b290cb1c7161"
      },
      "source": [
        "fold = 2\n",
        "FLAGS = {}\n",
        "def mp_wrapper(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    world_func(fold)\n",
        "\n",
        "xmp.spawn(mp_wrapper, args=(FLAGS,), nprocs=8, start_method='fork')\n",
        "\n",
        "# run inference\n",
        "make_inference(fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception in device=TPU:0: Cannot replicate if number of devices (1) is different from 8\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 330, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "Exception in device=TPU:1: Cannot replicate if number of devices (1) is different from 8\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    _setup_replication()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 316, in _setup_replication\n",
            "    xm.set_replication(device, [device])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 330, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "Exception in device=TPU:2: Cannot replicate if number of devices (1) is different from 8\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    _setup_replication()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 316, in _setup_replication\n",
            "    xm.set_replication(device, [device])\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 294, in set_replication\n",
            "    replication_devices = xla_replication_devices(devices)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 294, in set_replication\n",
            "    replication_devices = xla_replication_devices(devices)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 267, in xla_replication_devices\n",
            "    format(len(local_devices), len(kind_devices)))\n",
            "Exception in device=TPU:3: Cannot replicate if number of devices (1) is different from 8\n",
            "RuntimeError: Cannot replicate if number of devices (1) is different from 8\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 267, in xla_replication_devices\n",
            "    format(len(local_devices), len(kind_devices)))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 330, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    _setup_replication()\n",
            "Traceback (most recent call last):\n",
            "RuntimeError: Cannot replicate if number of devices (1) is different from 8\n",
            "Exception in device=TPU:4: Cannot replicate if number of devices (1) is different from 8\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 316, in _setup_replication\n",
            "    xm.set_replication(device, [device])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 330, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 294, in set_replication\n",
            "    replication_devices = xla_replication_devices(devices)\n",
            "Exception in device=TPU:5: Cannot replicate if number of devices (1) is different from 8\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 267, in xla_replication_devices\n",
            "    format(len(local_devices), len(kind_devices)))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    _setup_replication()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 330, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 316, in _setup_replication\n",
            "    xm.set_replication(device, [device])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    _setup_replication()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 330, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "RuntimeError: Cannot replicate if number of devices (1) is different from 8\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 294, in set_replication\n",
            "    replication_devices = xla_replication_devices(devices)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 316, in _setup_replication\n",
            "    xm.set_replication(device, [device])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 267, in xla_replication_devices\n",
            "    format(len(local_devices), len(kind_devices)))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    _setup_replication()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 294, in set_replication\n",
            "    replication_devices = xla_replication_devices(devices)\n",
            "RuntimeError: Cannot replicate if number of devices (1) is different from 8\n",
            "Exception in device=TPU:6: Cannot replicate if number of devices (1) is different from 8\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 267, in xla_replication_devices\n",
            "    format(len(local_devices), len(kind_devices)))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 316, in _setup_replication\n",
            "    xm.set_replication(device, [device])\n",
            "RuntimeError: Cannot replicate if number of devices (1) is different from 8\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 294, in set_replication\n",
            "    replication_devices = xla_replication_devices(devices)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 267, in xla_replication_devices\n",
            "    format(len(local_devices), len(kind_devices)))\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 330, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "RuntimeError: Cannot replicate if number of devices (1) is different from 8\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    _setup_replication()\n",
            "Exception in device=TPU:7: Cannot replicate if number of devices (1) is different from 8\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 316, in _setup_replication\n",
            "    xm.set_replication(device, [device])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 294, in set_replication\n",
            "    replication_devices = xla_replication_devices(devices)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 330, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 267, in xla_replication_devices\n",
            "    format(len(local_devices), len(kind_devices)))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    _setup_replication()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 316, in _setup_replication\n",
            "    xm.set_replication(device, [device])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 294, in set_replication\n",
            "    replication_devices = xla_replication_devices(devices)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 267, in xla_replication_devices\n",
            "    format(len(local_devices), len(kind_devices)))\n",
            "RuntimeError: Cannot replicate if number of devices (1) is different from 8\n",
            "RuntimeError: Cannot replicate if number of devices (1) is different from 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d25e70178411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mworld_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 raise Exception(\n\u001b[1;32m    112\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: process 0 terminated with exit code 17"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4h1g7q3tJCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTux2zlftI_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_FsP3t4tI7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx4S9Soh2R-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "492acc1d6fb44cec89a18212b40acb14",
            "ecaaf99190a34729b907f34897bb9ece",
            "4d49e9fd3dd149aaa38c1e5bbcb1669b",
            "920cdb7d0c134c359ba0576a2fddce5e",
            "ef3eb3e71580499b9d07b3e04a0f08a9",
            "b6f4012afbcb4dd9a9e8c1908ca2e2e7",
            "08d5fb96ee8f4362a573281a5067398c",
            "830af8122f3443f4bf28ac3ea44f7553"
          ]
        },
        "outputId": "b2c5c658-5f25-4533-c049-e148d673fc81"
      },
      "source": [
        "fold = 0\n",
        "FLAGS = {}\n",
        "def mp_wrapper(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    world_func(fold)\n",
        "\n",
        "xmp.spawn(mp_wrapper, args=(FLAGS,), nprocs=8, start_method='fork')\n",
        "\n",
        "# run inference\n",
        "make_inference(fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Fold 0\n",
            "num_train_steps = 1592, world_size = 8\n",
            "Training...\n",
            "Batch: 0, Training loss: 3.33591365814209\n",
            "Batch: 100, Training loss: 2.3373561082500043\n",
            "Batch: 200, Training loss: 1.8479502334523557\n",
            "Training time: 343.19077825546265 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.9810035228729248\n",
            "Batch: 100, Evaluation loss: 0.7740882924287626\n",
            "Batch: 200, Evaluation loss: 0.7900369395664082\n",
            "Evaluation time: 110.76497888565063 secs\n",
            "VALID ACCURACY: 0.8307783018867925\n",
            "VALID MACRO_F1: 0.7765953461835677\n",
            "Validation score improved (-inf --> 0.7765953461835677). Saving model!\n",
            "Training...\n",
            "Batch: 0, Training loss: 1.0125924348831177\n",
            "Batch: 100, Training loss: 0.7501974397956734\n",
            "Batch: 200, Training loss: 0.718463994377288\n",
            "Training time: 318.9730176925659 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.759476363658905\n",
            "Batch: 100, Evaluation loss: 0.4876207639970402\n",
            "Batch: 200, Evaluation loss: 0.4936477908151067\n",
            "Evaluation time: 119.61412382125854 secs\n",
            "VALID ACCURACY: 0.8787735849056604\n",
            "VALID MACRO_F1: 0.844918193919458\n",
            "Validation score improved (0.7765953461835677 --> 0.844918193919458). Saving model!\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.839164137840271\n",
            "Batch: 100, Training loss: 0.4869472781325331\n",
            "Batch: 200, Training loss: 0.49085063639268356\n",
            "Training time: 320.50124311447144 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.5028712749481201\n",
            "Batch: 100, Evaluation loss: 0.3614694046797139\n",
            "Batch: 200, Evaluation loss: 0.370210969107068\n",
            "Evaluation time: 120.85076594352722 secs\n",
            "VALID ACCURACY: 0.905188679245283\n",
            "VALID MACRO_F1: 0.891325727547128\n",
            "Validation score improved (0.844918193919458 --> 0.891325727547128). Saving model!\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.7246191501617432\n",
            "Batch: 100, Training loss: 0.3662664972171925\n",
            "Batch: 200, Training loss: 0.3775729676384238\n",
            "Training time: 325.7410786151886 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.34474343061447144\n",
            "Batch: 100, Evaluation loss: 0.27547043960283296\n",
            "Batch: 200, Evaluation loss: 0.28369982718531767\n",
            "Evaluation time: 111.76575565338135 secs\n",
            "VALID ACCURACY: 0.9287735849056604\n",
            "VALID MACRO_F1: 0.918663658273253\n",
            "Validation score improved (0.891325727547128 --> 0.918663658273253). Saving model!\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.38319849967956543\n",
            "Batch: 100, Training loss: 0.2936158882509364\n",
            "Batch: 200, Training loss: 0.3042290127692531\n",
            "Training time: 325.9265446662903 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.27217644453048706\n",
            "Batch: 100, Evaluation loss: 0.20591189597945403\n",
            "Batch: 200, Evaluation loss: 0.2196197217117198\n",
            "Evaluation time: 111.96010518074036 secs\n",
            "VALID ACCURACY: 0.9485849056603773\n",
            "VALID MACRO_F1: 0.9381633375489683\n",
            "Validation score improved (0.918663658273253 --> 0.9381633375489683). Saving model!\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.39471977949142456\n",
            "Batch: 100, Training loss: 0.2456042468547821\n",
            "Batch: 200, Training loss: 0.25537049614671453\n",
            "Training time: 326.47039270401 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.17959780991077423\n",
            "Batch: 100, Evaluation loss: 0.18080715838782857\n",
            "Batch: 200, Evaluation loss: 0.19757238241718778\n",
            "Evaluation time: 122.69856429100037 secs\n",
            "VALID ACCURACY: 0.9531839622641509\n",
            "VALID MACRO_F1: 0.9435681522692039\n",
            "Validation score improved (0.9381633375489683 --> 0.9435681522692039). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "492acc1d6fb44cec89a18212b40acb14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Submission file saved at: \n",
            " /content/drive/My Drive/Rakuten/dataset/'y_test_task1_phase1_pred_fold0.tsv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3MHGFTqWp5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1839e51c-3bae-43ca-a232-64011e1a74e9"
      },
      "source": [
        "fold = 1\n",
        "FLAGS = {}\n",
        "def mp_wrapper(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    world_func(fold)\n",
        "\n",
        "xmp.spawn(mp_wrapper, args=(FLAGS,), nprocs=8, start_method='fork')\n",
        "\n",
        "# run inference\n",
        "make_inference(fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Fold 1\n",
            "num_train_steps = 2653, world_size = 8\n",
            "--------------------------------------------------\n",
            "Running Epoch #0 \n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 3.345763683319092\n",
            "Batch: 100, Training loss: 2.3367084984732145\n",
            "Batch: 200, Training loss: 1.7959325710932414\n",
            "Training time: 421.09 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.6838085055351257\n",
            "Batch: 100, Evaluation loss: 0.743703978781653\n",
            "Batch: 200, Evaluation loss: 0.7319193085034689\n",
            "Evaluation time: 127.83 secs \n",
            "\n",
            "VALID ACCURACY: 0.8461084905660378\n",
            "VALID MACRO_F1: 0.7982494137308145\n",
            "Validation score improved (-inf --> 0.7982494137308145). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #1 🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.7143270373344421\n",
            "Batch: 100, Training loss: 0.7104518386987176\n",
            "Batch: 200, Training loss: 0.653398674667178\n",
            "Training time: 343.51 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.509303867816925\n",
            "Batch: 100, Evaluation loss: 0.43844525375873733\n",
            "Batch: 200, Evaluation loss: 0.42717774393991453\n",
            "Evaluation time: 121.44 secs \n",
            "\n",
            "VALID ACCURACY: 0.8963443396226415\n",
            "VALID MACRO_F1: 0.866577822375084\n",
            "Validation score improved (0.7982494137308145 --> 0.866577822375084). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #2 🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.5253803730010986\n",
            "Batch: 100, Training loss: 0.4697601563564622\n",
            "Batch: 200, Training loss: 0.4453773093386669\n",
            "Training time: 339.92 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.5007951855659485\n",
            "Batch: 100, Evaluation loss: 0.322770381991816\n",
            "Batch: 200, Evaluation loss: 0.3128377388958907\n",
            "Evaluation time: 124.85 secs \n",
            "\n",
            "VALID ACCURACY: 0.9228773584905661\n",
            "VALID MACRO_F1: 0.9060744527186487\n",
            "Validation score improved (0.866577822375084 --> 0.9060744527186487). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #3 🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.49561047554016113\n",
            "Batch: 100, Training loss: 0.356582044522361\n",
            "Batch: 200, Training loss: 0.3376175625370213\n",
            "Training time: 344.7 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.4349507987499237\n",
            "Batch: 100, Evaluation loss: 0.25995774972851915\n",
            "Batch: 200, Evaluation loss: 0.24555347735683122\n",
            "Evaluation time: 122.05 secs \n",
            "\n",
            "VALID ACCURACY: 0.9403301886792453\n",
            "VALID MACRO_F1: 0.9275969988163913\n",
            "Validation score improved (0.9060744527186487 --> 0.9275969988163913). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #4 🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.46695950627326965\n",
            "Batch: 100, Training loss: 0.2786535345534287\n",
            "Batch: 200, Training loss: 0.26991129829664134\n",
            "Training time: 342.01 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.34501466155052185\n",
            "Batch: 100, Evaluation loss: 0.21100549763160767\n",
            "Batch: 200, Evaluation loss: 0.19413666524437825\n",
            "Evaluation time: 126.18 secs \n",
            "\n",
            "VALID ACCURACY: 0.9521226415094339\n",
            "VALID MACRO_F1: 0.9432237282090511\n",
            "Validation score improved (0.9275969988163913 --> 0.9432237282090511). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #5 🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.5477163791656494\n",
            "Batch: 100, Training loss: 0.25365493481628376\n",
            "Batch: 200, Training loss: 0.24515953786041014\n",
            "Training time: 343.51 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.17855754494667053\n",
            "Batch: 100, Evaluation loss: 0.1573621075194661\n",
            "Batch: 200, Evaluation loss: 0.1471224274597506\n",
            "Evaluation time: 120.95 secs \n",
            "\n",
            "VALID ACCURACY: 0.964504716981132\n",
            "VALID MACRO_F1: 0.9553591854161795\n",
            "Validation score improved (0.9432237282090511 --> 0.9553591854161795). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #6 🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.2215905338525772\n",
            "Batch: 100, Training loss: 0.1857256964033488\n",
            "Batch: 200, Training loss: 0.17808967234742878\n",
            "Training time: 344.55 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.0698423981666565\n",
            "Batch: 100, Evaluation loss: 0.12352215885968491\n",
            "Batch: 200, Evaluation loss: 0.11591922555730413\n",
            "Evaluation time: 125.62 secs \n",
            "\n",
            "VALID ACCURACY: 0.9724056603773585\n",
            "VALID MACRO_F1: 0.9657895967953535\n",
            "Validation score improved (0.9553591854161795 --> 0.9657895967953535). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #7 🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.1321537345647812\n",
            "Batch: 100, Training loss: 0.14501023062016113\n",
            "Batch: 200, Training loss: 0.14120695555573376\n",
            "Training time: 349.42 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.03036690317094326\n",
            "Batch: 100, Evaluation loss: 0.09626340735150446\n",
            "Batch: 200, Evaluation loss: 0.08943437908159856\n",
            "Evaluation time: 125.92 secs \n",
            "\n",
            "VALID ACCURACY: 0.9795990566037736\n",
            "VALID MACRO_F1: 0.9744966710134686\n",
            "Validation score improved (0.9657895967953535 --> 0.9744966710134686). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #8 🔥🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.19064906239509583\n",
            "Batch: 100, Training loss: 0.1302018482053634\n",
            "Batch: 200, Training loss: 0.12727096373799132\n",
            "Training time: 345.49 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.03741109371185303\n",
            "Batch: 100, Evaluation loss: 0.07910583572148687\n",
            "Batch: 200, Evaluation loss: 0.07349124690286112\n",
            "Evaluation time: 124.43 secs \n",
            "\n",
            "VALID ACCURACY: 0.9850235849056603\n",
            "VALID MACRO_F1: 0.9809654673399494\n",
            "Validation score improved (0.9744966710134686 --> 0.9809654673399494). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #9 🔥🔥🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.02412455528974533\n",
            "Batch: 100, Training loss: 0.11845956144319607\n",
            "Batch: 200, Training loss: 0.11049921183258443\n",
            "Training time: 344.83 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.062653549015522\n",
            "Batch: 100, Evaluation loss: 0.07348630608677274\n",
            "Batch: 200, Evaluation loss: 0.06943320389837027\n",
            "Evaluation time: 124.18 secs \n",
            "\n",
            "VALID ACCURACY: 0.9850235849056603\n",
            "VALID MACRO_F1: 0.9808353797913113\n",
            "EarlyStopping counter: 1 out of 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in device=TPU:5: tensorflow/compiler/xla/xla_client/mesh_service.cc:294 : Failed to meet rendezvous 'torch_xla.core.xla_model.save': Socket closed (14)\n",
            "Exception in device=TPU:2: tensorflow/compiler/xla/xla_client/mesh_service.cc:294 : Failed to meet rendezvous 'torch_xla.core.xla_model.save': Socket closed (14)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"<ipython-input-67-e55a66988613>\", line 5, in mp_wrapper\n",
            "    world_func(fold)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-64-501291fcc907>\", line 181, in world_func\n",
            "    es(macro_f1, model, model_path=model_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"<ipython-input-12-a3626b0087a3>\", line 31, in __call__\n",
            "    self.save_checkpoint(epoch_score, model, model_path)\n",
            "  File \"<ipython-input-67-e55a66988613>\", line 5, in mp_wrapper\n",
            "    world_func(fold)\n",
            "  File \"<ipython-input-12-a3626b0087a3>\", line 38, in save_checkpoint\n",
            "    xm.save(model.state_dict(), model_path)\n",
            "  File \"<ipython-input-64-501291fcc907>\", line 181, in world_func\n",
            "    es(macro_f1, model, model_path=model_path)\n",
            "  File \"<ipython-input-12-a3626b0087a3>\", line 31, in __call__\n",
            "    self.save_checkpoint(epoch_score, model, model_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 635, in save\n",
            "    rendezvous('torch_xla.core.xla_model.save')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 679, in rendezvous\n",
            "    return torch_xla._XLAC._xla_rendezvous(get_ordinal(), tag, payload, replicas)\n",
            "  File \"<ipython-input-12-a3626b0087a3>\", line 38, in save_checkpoint\n",
            "    xm.save(model.state_dict(), model_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 635, in save\n",
            "    rendezvous('torch_xla.core.xla_model.save')\n",
            "RuntimeError: tensorflow/compiler/xla/xla_client/mesh_service.cc:294 : Failed to meet rendezvous 'torch_xla.core.xla_model.save': Socket closed (14)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 679, in rendezvous\n",
            "    return torch_xla._XLAC._xla_rendezvous(get_ordinal(), tag, payload, replicas)\n",
            "RuntimeError: tensorflow/compiler/xla/xla_client/mesh_service.cc:294 : Failed to meet rendezvous 'torch_xla.core.xla_model.save': Socket closed (14)\n",
            "Exception in device=TPU:7: tensorflow/compiler/xla/xla_client/mesh_service.cc:294 : Failed to meet rendezvous 'torch_xla.core.xla_model.save': Socket closed (14)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"<ipython-input-67-e55a66988613>\", line 5, in mp_wrapper\n",
            "    world_func(fold)\n",
            "  File \"<ipython-input-64-501291fcc907>\", line 181, in world_func\n",
            "    es(macro_f1, model, model_path=model_path)\n",
            "  File \"<ipython-input-12-a3626b0087a3>\", line 31, in __call__\n",
            "    self.save_checkpoint(epoch_score, model, model_path)\n",
            "  File \"<ipython-input-12-a3626b0087a3>\", line 38, in save_checkpoint\n",
            "    xm.save(model.state_dict(), model_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 635, in save\n",
            "    rendezvous('torch_xla.core.xla_model.save')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 679, in rendezvous\n",
            "    return torch_xla._XLAC._xla_rendezvous(get_ordinal(), tag, payload, replicas)\n",
            "RuntimeError: tensorflow/compiler/xla/xla_client/mesh_service.cc:294 : Failed to meet rendezvous 'torch_xla.core.xla_model.save': Socket closed (14)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-e55a66988613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mworld_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 raise Exception(\n\u001b[1;32m    112\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: process 2 terminated with exit code 17"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kafj_itFdK0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "916f1ea545b2480ba212ee67aed4f49f",
            "6386b091206645ae96252184488e908a",
            "a2e5de9fcf29434583fc711fb30d1de5",
            "d0e716747b024feb862ce85f14cd55bc",
            "94879d4104b647e5a2553f1f3ee93e02",
            "340d1ffd1b8d4f7886b81d720f407dab",
            "c1dec34a4bd9487180967794d7d8bdff",
            "f79206e5283245f392fb2698a8d90b84"
          ]
        },
        "outputId": "6e18f99c-2571-45ad-ddb6-4892bd17208c"
      },
      "source": [
        "make_inference(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "916f1ea545b2480ba212ee67aed4f49f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Submission file saved at: \n",
            " /content/drive/My Drive/Rakuten/dataset/'y_test_task1_phase1_pred_fold1.tsv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eet0oAfQd7gI",
        "colab_type": "text"
      },
      "source": [
        "Model 1 86.94 on LB, 98 on CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzxlTJ0VWra-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8056c47f010249b9bc1eb88d4a36cbf5",
            "ffbadfe7de084975a1ebaa55ae0b7a69",
            "b996b107b7fb42cfbe94b18e9089b51a",
            "647a6e5e46a642039057e1bcc6f7a16e",
            "03c5e38a7d974a7d926097757ada7719",
            "e551f67ed75b44478f7ef3105f65b97b",
            "345c35e4e6864102ae57e887d6f876b9",
            "8e594aea09434a129a256b407b497083"
          ]
        },
        "outputId": "1c7fc9b4-0aab-410c-c847-ceb5bad768d9"
      },
      "source": [
        "fold = 2\n",
        "FLAGS = {}\n",
        "def mp_wrapper(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    world_func(fold)\n",
        "\n",
        "xmp.spawn(mp_wrapper, args=(FLAGS,), nprocs=8, start_method='fork')\n",
        "\n",
        "# run inference\n",
        "make_inference(fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Fold 2\n",
            "num_train_steps = 2653, world_size = 8\n",
            "--------------------------------------------------\n",
            "Running Epoch #0 \n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 3.3442208766937256\n",
            "Batch: 100, Training loss: 2.3326966514681824\n",
            "Batch: 200, Training loss: 1.7737489384205187\n",
            "Training time: 362.49 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.5701291561126709\n",
            "Batch: 100, Evaluation loss: 0.7560484521459825\n",
            "Batch: 200, Evaluation loss: 0.7328266193024555\n",
            "Evaluation time: 116.84 secs \n",
            "\n",
            "VALID ACCURACY: 0.845754716981132\n",
            "VALID MACRO_F1: 0.8023497792939893\n",
            "Validation score improved (-inf --> 0.8023497792939893). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #1 🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.5969314575195312\n",
            "Batch: 100, Training loss: 0.7191913231174545\n",
            "Batch: 200, Training loss: 0.6337611312741664\n",
            "Training time: 343.47 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.3209414482116699\n",
            "Batch: 100, Evaluation loss: 0.4596515532472346\n",
            "Batch: 200, Evaluation loss: 0.430260017069418\n",
            "Evaluation time: 120.02 secs \n",
            "\n",
            "VALID ACCURACY: 0.8935141509433963\n",
            "VALID MACRO_F1: 0.8710493826799742\n",
            "Validation score improved (0.8023497792939893 --> 0.8710493826799742). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #2 🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.4216926693916321\n",
            "Batch: 100, Training loss: 0.4544799444403979\n",
            "Batch: 200, Training loss: 0.4160515484747602\n",
            "Training time: 329.7 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.22797562181949615\n",
            "Batch: 100, Evaluation loss: 0.3181390784459539\n",
            "Batch: 200, Evaluation loss: 0.2996280915405027\n",
            "Evaluation time: 120.38 secs \n",
            "\n",
            "VALID ACCURACY: 0.9258254716981132\n",
            "VALID MACRO_F1: 0.9133518316212675\n",
            "Validation score improved (0.8710493826799742 --> 0.9133518316212675). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #3 🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.23316943645477295\n",
            "Batch: 100, Training loss: 0.3498690649867058\n",
            "Batch: 200, Training loss: 0.32308448050449146\n",
            "Training time: 335.88 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.17470411956310272\n",
            "Batch: 100, Evaluation loss: 0.22970696125585255\n",
            "Batch: 200, Evaluation loss: 0.22416889775006926\n",
            "Evaluation time: 123.47 secs \n",
            "\n",
            "VALID ACCURACY: 0.9472877358490566\n",
            "VALID MACRO_F1: 0.9397641665823249\n",
            "Validation score improved (0.9133518316212675 --> 0.9397641665823249). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #4 🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.20677168667316437\n",
            "Batch: 100, Training loss: 0.26417055973174547\n",
            "Batch: 200, Training loss: 0.25391219650853925\n",
            "Training time: 341.21 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.1472504884004593\n",
            "Batch: 100, Evaluation loss: 0.17524422826890898\n",
            "Batch: 200, Evaluation loss: 0.17509837468984116\n",
            "Evaluation time: 116.44 secs \n",
            "\n",
            "VALID ACCURACY: 0.9616745283018868\n",
            "VALID MACRO_F1: 0.9582508694071815\n",
            "Validation score improved (0.9397641665823249 --> 0.9582508694071815). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #5 🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.18414250016212463\n",
            "Batch: 100, Training loss: 0.1998986684818669\n",
            "Batch: 200, Training loss: 0.19807643791781135\n",
            "Training time: 340.1 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.04211653769016266\n",
            "Batch: 100, Evaluation loss: 0.14081554288173667\n",
            "Batch: 200, Evaluation loss: 0.1426690585484997\n",
            "Evaluation time: 114.02 secs \n",
            "\n",
            "VALID ACCURACY: 0.9682783018867924\n",
            "VALID MACRO_F1: 0.9639975473485207\n",
            "Validation score improved (0.9582508694071815 --> 0.9639975473485207). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #6 🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.06373383104801178\n",
            "Batch: 100, Training loss: 0.1638847451730825\n",
            "Batch: 200, Training loss: 0.16346041225730928\n",
            "Training time: 344.12 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.03956044837832451\n",
            "Batch: 100, Evaluation loss: 0.10894742028990595\n",
            "Batch: 200, Evaluation loss: 0.11303039362181479\n",
            "Evaluation time: 122.09 secs \n",
            "\n",
            "VALID ACCURACY: 0.9754716981132076\n",
            "VALID MACRO_F1: 0.9739291951560948\n",
            "Validation score improved (0.9639975473485207 --> 0.9739291951560948). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #7 🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.03398076817393303\n",
            "Batch: 100, Training loss: 0.12427051985027766\n",
            "Batch: 200, Training loss: 0.1287254080713833\n",
            "Training time: 341.66 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.035603225231170654\n",
            "Batch: 100, Evaluation loss: 0.07892915346466078\n",
            "Batch: 200, Evaluation loss: 0.0875988727833946\n",
            "Evaluation time: 113.65 secs \n",
            "\n",
            "VALID ACCURACY: 0.9831367924528301\n",
            "VALID MACRO_F1: 0.9819932559506903\n",
            "Validation score improved (0.9739291951560948 --> 0.9819932559506903). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #8 🔥🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.05062311515212059\n",
            "Batch: 100, Training loss: 0.100320999353829\n",
            "Batch: 200, Training loss: 0.10706025124782353\n",
            "Training time: 337.44 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.026577042415738106\n",
            "Batch: 100, Evaluation loss: 0.06421473978253284\n",
            "Batch: 200, Evaluation loss: 0.07312891555866644\n",
            "Evaluation time: 117.24 secs \n",
            "\n",
            "VALID ACCURACY: 0.9857311320754717\n",
            "VALID MACRO_F1: 0.9850111764642788\n",
            "Validation score improved (0.9819932559506903 --> 0.9850111764642788). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #9 🔥🔥🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.1477784514427185\n",
            "Batch: 100, Training loss: 0.08705251160455812\n",
            "Batch: 200, Training loss: 0.09374889379265297\n",
            "Training time: 337.25 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.022077960893511772\n",
            "Batch: 100, Evaluation loss: 0.05627436348522949\n",
            "Batch: 200, Evaluation loss: 0.06611078479952777\n",
            "Evaluation time: 127.21 secs \n",
            "\n",
            "VALID ACCURACY: 0.9873820754716981\n",
            "VALID MACRO_F1: 0.9864687895616358\n",
            "Validation score improved (0.9850111764642788 --> 0.9864687895616358). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8056c47f010249b9bc1eb88d4a36cbf5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Submission file saved at: \n",
            " /content/drive/My Drive/Rakuten/dataset/'y_test_task1_phase1_pred_fold2.tsv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMvFErCJWtRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "90a298d7d3e2419d80deda549cf2ba3f",
            "77ede916532f4d20937aa747d9c0b552",
            "27c0551dcd7e4ba9b1e7854c9c535149",
            "9b3f3213a4974c698a642835ab273933",
            "b6e946f03ad74e90ae86c9c08500dfd8",
            "0a45c1bf37654f52ad8b5bfb14e8e948",
            "66f3a918da204e6d8bb2a7351002b731",
            "3283cc45ffb043edb29acb3daf3310fd"
          ]
        },
        "outputId": "0fa2cc8e-b305-439c-8158-f597ef74c89c"
      },
      "source": [
        "fold = 3\n",
        "FLAGS = {}\n",
        "def mp_wrapper(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    world_func(fold)\n",
        "\n",
        "xmp.spawn(mp_wrapper, args=(FLAGS,), nprocs=8, start_method='fork')\n",
        "\n",
        "# run inference\n",
        "make_inference(fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Fold 3\n",
            "num_train_steps = 2653, world_size = 8\n",
            "--------------------------------------------------\n",
            "Running Epoch #0 \n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 3.4504196643829346\n",
            "Batch: 100, Training loss: 2.318692701877934\n",
            "Batch: 200, Training loss: 1.772972083803433\n",
            "Training time: 345.6 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.7343528866767883\n",
            "Batch: 100, Evaluation loss: 0.7351292678625276\n",
            "Batch: 200, Evaluation loss: 0.724468876918157\n",
            "Evaluation time: 110.17 secs \n",
            "\n",
            "VALID ACCURACY: 0.8474056603773585\n",
            "VALID MACRO_F1: 0.7985932520183028\n",
            "Validation score improved (-inf --> 0.7985932520183028). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #1 🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.7009313106536865\n",
            "Batch: 100, Training loss: 0.698773587989335\n",
            "Batch: 200, Training loss: 0.6408535894469836\n",
            "Training time: 340.63 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.4171871542930603\n",
            "Batch: 100, Evaluation loss: 0.45884515404111087\n",
            "Batch: 200, Evaluation loss: 0.44135924995835146\n",
            "Evaluation time: 126.57 secs \n",
            "\n",
            "VALID ACCURACY: 0.8928066037735849\n",
            "VALID MACRO_F1: 0.8731278656825909\n",
            "Validation score improved (0.7985932520183028 --> 0.8731278656825909). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #2 🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.4939309358596802\n",
            "Batch: 100, Training loss: 0.47950335215814044\n",
            "Batch: 200, Training loss: 0.44763872368418756\n",
            "Training time: 331.96 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.3113689124584198\n",
            "Batch: 100, Evaluation loss: 0.3363833707010392\n",
            "Batch: 200, Evaluation loss: 0.3205487602089175\n",
            "Evaluation time: 121.81 secs \n",
            "\n",
            "VALID ACCURACY: 0.9196933962264151\n",
            "VALID MACRO_F1: 0.905732769104457\n",
            "Validation score improved (0.8731278656825909 --> 0.905732769104457). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #3 🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.3221159875392914\n",
            "Batch: 100, Training loss: 0.3696462800449664\n",
            "Batch: 200, Training loss: 0.34190715882760375\n",
            "Training time: 327.8 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.21351829171180725\n",
            "Batch: 100, Evaluation loss: 0.259042680115983\n",
            "Batch: 200, Evaluation loss: 0.24592499030911508\n",
            "Evaluation time: 123.48 secs \n",
            "\n",
            "VALID ACCURACY: 0.9408018867924528\n",
            "VALID MACRO_F1: 0.9290379226769764\n",
            "Validation score improved (0.905732769104457 --> 0.9290379226769764). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #4 🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.41033241152763367\n",
            "Batch: 100, Training loss: 0.27690948324628395\n",
            "Batch: 200, Training loss: 0.26450197341207843\n",
            "Training time: 340.32 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.13682429492473602\n",
            "Batch: 100, Evaluation loss: 0.19898332496828372\n",
            "Batch: 200, Evaluation loss: 0.1879206424514156\n",
            "Evaluation time: 123.11 secs \n",
            "\n",
            "VALID ACCURACY: 0.9556603773584905\n",
            "VALID MACRO_F1: 0.9477781789108678\n",
            "Validation score improved (0.9290379226769764 --> 0.9477781789108678). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #5 🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.22544635832309723\n",
            "Batch: 100, Training loss: 0.22618842084366497\n",
            "Batch: 200, Training loss: 0.2152375194860335\n",
            "Training time: 346.09 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.09374525398015976\n",
            "Batch: 100, Evaluation loss: 0.1553925894348338\n",
            "Batch: 200, Evaluation loss: 0.14968584281443365\n",
            "Evaluation time: 122.31 secs \n",
            "\n",
            "VALID ACCURACY: 0.964622641509434\n",
            "VALID MACRO_F1: 0.958508866870279\n",
            "Validation score improved (0.9477781789108678 --> 0.958508866870279). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #6 🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.1092914491891861\n",
            "Batch: 100, Training loss: 0.17530876918151828\n",
            "Batch: 200, Training loss: 0.17034949016622938\n",
            "Training time: 337.51 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.03425624221563339\n",
            "Batch: 100, Evaluation loss: 0.12149650367474792\n",
            "Batch: 200, Evaluation loss: 0.11931489813906043\n",
            "Evaluation time: 118.98 secs \n",
            "\n",
            "VALID ACCURACY: 0.9741745283018868\n",
            "VALID MACRO_F1: 0.9697092432173817\n",
            "Validation score improved (0.958508866870279 --> 0.9697092432173817). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #7 🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.23149050772190094\n",
            "Batch: 100, Training loss: 0.1554037395237696\n",
            "Batch: 200, Training loss: 0.14597074406694122\n",
            "Training time: 341.38 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.028240272775292397\n",
            "Batch: 100, Evaluation loss: 0.09890301448136272\n",
            "Batch: 200, Evaluation loss: 0.09603174093795654\n",
            "Evaluation time: 128.38 secs \n",
            "\n",
            "VALID ACCURACY: 0.98125\n",
            "VALID MACRO_F1: 0.9771773399787106\n",
            "Validation score improved (0.9697092432173817 --> 0.9771773399787106). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #8 🔥🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.05910394340753555\n",
            "Batch: 100, Training loss: 0.12208536132653751\n",
            "Batch: 200, Training loss: 0.11724724893027277\n",
            "Training time: 346.34 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.0267699733376503\n",
            "Batch: 100, Evaluation loss: 0.08161912756132902\n",
            "Batch: 200, Evaluation loss: 0.0817390283273153\n",
            "Evaluation time: 122.5 secs \n",
            "\n",
            "VALID ACCURACY: 0.9838443396226415\n",
            "VALID MACRO_F1: 0.9804127979018783\n",
            "Validation score improved (0.9771773399787106 --> 0.9804127979018783). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #9 🔥🔥🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.029535094276070595\n",
            "Batch: 100, Training loss: 0.10669359342554713\n",
            "Batch: 200, Training loss: 0.10394616305957831\n",
            "Training time: 340.08 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.02731320634484291\n",
            "Batch: 100, Evaluation loss: 0.07026872378174621\n",
            "Batch: 200, Evaluation loss: 0.07312971130198803\n",
            "Evaluation time: 119.13 secs \n",
            "\n",
            "VALID ACCURACY: 0.9847877358490567\n",
            "VALID MACRO_F1: 0.9817079729493388\n",
            "Validation score improved (0.9804127979018783 --> 0.9817079729493388). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90a298d7d3e2419d80deda549cf2ba3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Submission file saved at: \n",
            " /content/drive/My Drive/Rakuten/dataset/'y_test_task1_phase1_pred_fold3.tsv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3nvP_fhWuiK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d71af64b-2f85-43b3-fee8-daf41f318ca1"
      },
      "source": [
        "fold = 4\n",
        "FLAGS = {}\n",
        "def mp_wrapper(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    world_func(fold)\n",
        "\n",
        "xmp.spawn(mp_wrapper, args=(FLAGS,), nprocs=8, start_method='fork')\n",
        "\n",
        "# run inference\n",
        "make_inference(fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Fold 4\n",
            "num_train_steps = 2653, world_size = 8\n",
            "--------------------------------------------------\n",
            "Running Epoch #0 \n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 3.3859407901763916\n",
            "Batch: 100, Training loss: 2.3578107888155646\n",
            "Batch: 200, Training loss: 1.806221757955219\n",
            "Training time: 359.04 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.821690022945404\n",
            "Batch: 100, Evaluation loss: 0.7831577971430108\n",
            "Batch: 200, Evaluation loss: 0.759827194373999\n",
            "Evaluation time: 115.28 secs \n",
            "\n",
            "VALID ACCURACY: 0.8340801886792453\n",
            "VALID MACRO_F1: 0.7875756128803119\n",
            "Validation score improved (-inf --> 0.7875756128803119). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #1 🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.912128746509552\n",
            "Batch: 100, Training loss: 0.7352562018550268\n",
            "Batch: 200, Training loss: 0.6702111697760388\n",
            "Training time: 338.54 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.555725634098053\n",
            "Batch: 100, Evaluation loss: 0.48141206594386904\n",
            "Batch: 200, Evaluation loss: 0.4578124989769352\n",
            "Evaluation time: 126.05 secs \n",
            "\n",
            "VALID ACCURACY: 0.8849056603773585\n",
            "VALID MACRO_F1: 0.8555462641867746\n",
            "Validation score improved (0.7875756128803119 --> 0.8555462641867746). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #2 🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.5583845973014832\n",
            "Batch: 100, Training loss: 0.48773352949336024\n",
            "Batch: 200, Training loss: 0.46219758674576505\n",
            "Training time: 329.59 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.24502597749233246\n",
            "Batch: 100, Evaluation loss: 0.33808308684884913\n",
            "Batch: 200, Evaluation loss: 0.32234953251199344\n",
            "Evaluation time: 116.63 secs \n",
            "\n",
            "VALID ACCURACY: 0.9189858490566037\n",
            "VALID MACRO_F1: 0.9044301327484405\n",
            "Validation score improved (0.8555462641867746 --> 0.9044301327484405). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #3 🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.3684980571269989\n",
            "Batch: 100, Training loss: 0.36528398775228177\n",
            "Batch: 200, Training loss: 0.34773871832670855\n",
            "Training time: 336.06 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.18631333112716675\n",
            "Batch: 100, Evaluation loss: 0.2579935759232186\n",
            "Batch: 200, Evaluation loss: 0.2456857812456527\n",
            "Evaluation time: 119.74 secs \n",
            "\n",
            "VALID ACCURACY: 0.9398584905660378\n",
            "VALID MACRO_F1: 0.930385252898773\n",
            "Validation score improved (0.9044301327484405 --> 0.930385252898773). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #4 🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.3281523585319519\n",
            "Batch: 100, Training loss: 0.27791619418871283\n",
            "Batch: 200, Training loss: 0.26855115405288504\n",
            "Training time: 336.87 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.09555492550134659\n",
            "Batch: 100, Evaluation loss: 0.19551165866674763\n",
            "Batch: 200, Evaluation loss: 0.1878613047579776\n",
            "Evaluation time: 120.64 secs \n",
            "\n",
            "VALID ACCURACY: 0.9558962264150943\n",
            "VALID MACRO_F1: 0.9492755454092526\n",
            "Validation score improved (0.930385252898773 --> 0.9492755454092526). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #5 🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.2597261071205139\n",
            "Batch: 100, Training loss: 0.22119178302069703\n",
            "Batch: 200, Training loss: 0.21480395843214656\n",
            "Training time: 342.14 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.04588101804256439\n",
            "Batch: 100, Evaluation loss: 0.14723087530029882\n",
            "Batch: 200, Evaluation loss: 0.14287927060096123\n",
            "Evaluation time: 123.25 secs \n",
            "\n",
            "VALID ACCURACY: 0.9681603773584906\n",
            "VALID MACRO_F1: 0.9641609721234025\n",
            "Validation score improved (0.9492755454092526 --> 0.9641609721234025). Saving model!\n",
            "--------------------------------------------------\n",
            "Running Epoch #6 🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.08595043420791626\n",
            "Batch: 100, Training loss: 0.17758998608603926\n",
            "Batch: 200, Training loss: 0.22200622762650696\n",
            "Training time: 338.57 secs\n",
            "Evaluating...\n",
            "Batch: 0, Evaluation loss: 0.055096037685871124\n",
            "Batch: 100, Evaluation loss: 0.12459039708396585\n",
            "Batch: 200, Evaluation loss: 0.12572959663151806\n",
            "Evaluation time: 125.88 secs \n",
            "\n",
            "VALID ACCURACY: 0.9704009433962264\n",
            "VALID MACRO_F1: 0.9650789920216022\n",
            "EarlyStopping counter: 1 out of 4\n",
            "--------------------------------------------------\n",
            "Running Epoch #7 🔥🔥🔥🔥🔥🔥🔥\n",
            "-------------------------------------------------- \n",
            "\n",
            "Training...\n",
            "Batch: 0, Training loss: 0.36735403537750244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaWe0dgDAdDe",
        "colab_type": "text"
      },
      "source": [
        "If you using a big model, declare the model above multiprocessor func as a global. Also cahnge the pytorch_xla version to nightlyn"
      ]
    }
  ]
}